{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01eeb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4d97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505b90e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "15e50555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(256, activation='relu'),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "49174484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_pretrained_weights(epochs=5):\n",
    "    model = setup_model()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ",\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=epochs)\n",
    "    \n",
    "    _, pretrained_weights = tempfile.mkstemp('.tf')\n",
    "    \n",
    "    model.save_weights(pretrained_weights)\n",
    "    \n",
    "    return pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "19db1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pretrained_model():\n",
    "    model = setup_model()\n",
    "    pretrained_weights = setup_pretrained_weights()\n",
    "    model.load_weights(pretrained_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2af26c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2526 - accuracy: 0.9212\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1141 - accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0695 - accuracy: 0.9787\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0593 - accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "setup_model()\n",
    "pretrained_weights = setup_pretrained_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20e6d6",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e448f05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f34a416e1d0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "df1eb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,202\n",
      "Trainable params: 184,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a1790710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_6 (QuantizeL  (None, 28, 28)           3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_flatten_15 (QuantizeW  (None, 784)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_48 (QuantizeWra  (None, 128)              100485    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_49 (QuantizeWra  (None, 256)              33029     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dropout_15 (QuantizeW  (None, 256)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_50 (QuantizeWra  (None, 128)              32901     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_51 (QuantizeWra  (None, 128)              16517     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_52 (QuantizeWra  (None, 10)               1295      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,232\n",
      "Trainable params: 184,202\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quant_aware_model = tfmot.quantization.keras.quantize_model(base_model)\n",
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a6028575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_6 (QuantizeL  (None, 28, 28)           3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_flatten_15 (QuantizeW  (None, 784)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_48 (QuantizeWra  (None, 128)              100485    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_49 (QuantizeWra  (None, 256)              33029     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dropout_15 (QuantizeW  (None, 256)              1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_50 (QuantizeWra  (None, 128)              32901     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_51 (QuantizeWra  (None, 128)              16517     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_52 (QuantizeWra  (None, 10)               1295      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,232\n",
      "Trainable params: 184,202\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Q_aware model requires a recompile\n",
    "quant_aware_model.compile(optimizer='adam',\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "quant_aware_model.summary()\n",
    "\n",
    "# Note: the resulting model is quantization *aware* but not quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b0dfd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 18ms/step - loss: 0.0528 - accuracy: 0.9889 - val_loss: 0.0604 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34c37099c0>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We fine tune the model on a subset of the training data\n",
    "train_images_subset = x_train[0:1000]\n",
    "train_labels_subset = y_train[0:1000]\n",
    "\n",
    "quant_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                     batch_size=32, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "692a7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0676 - accuracy: 0.9798 - 572ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "q_aware_model_accuracy = model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21c27b",
   "metadata": {},
   "source": [
    "# TFLite Backend quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2a83e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, flatten_15_layer_call_fn, flatten_15_layer_call_and_return_conditional_losses, dense_48_layer_call_fn, dense_48_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo9au5rvo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo9au5rvo/assets\n",
      "/home/mkjm/.local/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-11-04 21:38:54.028446: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-11-04 21:38:54.028492: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-11-04 21:38:54.028757: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpo9au5rvo\n",
      "2023-11-04 21:38:54.035762: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-11-04 21:38:54.035796: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpo9au5rvo\n",
      "2023-11-04 21:38:54.061254: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-11-04 21:38:54.225996: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpo9au5rvo\n",
      "2023-11-04 21:38:54.264969: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 236213 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "bd555d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "      input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "      output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "      # Run predictions on every image in the \"test\" dataset.\n",
    "      prediction_digits = []\n",
    "      for i, test_image in enumerate(x_test):\n",
    "        if i % 1000 == 0:\n",
    "          print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "      print('\\n')\n",
    "      # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "      prediction_digits = np.array(prediction_digits)\n",
    "      accuracy = (prediction_digits == y_test).mean()\n",
    "      return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3a5da834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.9759\n",
      "Quant TF test accuracy: [0.06757364422082901, 0.9797999858856201]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "84d368bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnc3xdhf4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnc3xdhf4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model in Mb: 0.7056655883789062\n",
      "Quantized model in Mb: 0.18196868896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 21:39:11.116923: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-11-04 21:39:11.116962: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-11-04 21:39:11.117186: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpnc3xdhf4\n",
      "2023-11-04 21:39:11.119377: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-11-04 21:39:11.119401: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpnc3xdhf4\n",
      "2023-11-04 21:39:11.125933: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-11-04 21:39:11.162101: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpnc3xdhf4\n",
      "2023-11-04 21:39:11.175568: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 58383 microseconds.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# Create float TFLite model.\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "float_tflite_model = float_converter.convert()\n",
    "\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "\n",
    "with open(float_file, 'wb') as f:\n",
    "  f.write(float_tflite_model)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c72e5",
   "metadata": {},
   "source": [
    "# Quantizine only particular layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "25faf73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flatten_15', 'dense_48', 'dense_49', 'dropout_15', 'dense_50', 'dense_51', 'dense_52']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" (https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#quantize_some_layers)\n",
    "While this example used the type of the layer to decide what to quantize, \n",
    "the easiest way to quantize a particular layer is to set its name property,\n",
    "and look for that name in the clone_function.\n",
    "\"\"\"\n",
    "print([layer.name for layer in base_model.layers])\n",
    "\n",
    "to_be_quantized = ['dense48', 'dense_49']\n",
    "def quantization_wrapper(to_be_quantized):\n",
    "    \n",
    "    def quantize_layers(layer):\n",
    "        if layer.name in to_be_quantized.copy(): \n",
    "            print(f\"Layer {layer.name} will be quantized!\")\n",
    "            return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "\n",
    "        # If not quantized: identity function\n",
    "        return layer\n",
    "    \n",
    "    return quantize_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "816d11c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer dense_49 will be quantized!\n"
     ]
    }
   ],
   "source": [
    "annotated_model = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=quantization_wrapper(to_be_quantized)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "63d1f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " quant_dense_48 (QuantizeWra  (None, 128)              100483    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_49 (QuantizeWra  (None, 256)              33029     \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,210\n",
      "Trainable params: 184,202\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Note that the layer we quantized AND the layer immediately before it both\n",
    "# need to get quantized!\n",
    "quant_aware_model2 = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "# quant_aware_model2 = tfmot.quantization.keras.quantize_model(annotated_model)\n",
    "\n",
    "quant_aware_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3713f",
   "metadata": {},
   "source": [
    "### Fine-tuning the quant aware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "baf36b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile\n",
    "quant_aware_model2.compile(optimizer='adam',\n",
    "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "723f425c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 16ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.0234 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34a424d0f0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finetune\n",
    "quant_aware_model2.fit(train_images_subset, train_labels_subset,\n",
    "                     batch_size=32, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dc728ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0956 - accuracy: 0.9771 - 625ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "q_aware_model2_accuracy = quant_aware_model2.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ac70c",
   "metadata": {},
   "source": [
    "# Compare model sizes\n",
    "Note: we convert the model to the TFLite backend (to support 8bit quantization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "18a2f13f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, dense_48_layer_call_fn, dense_48_layer_call_and_return_conditional_losses, dense_49_layer_call_fn, dense_49_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyy_yy8a4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyy_yy8a4/assets\n",
      "/home/mkjm/.local/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-11-04 21:41:51.989484: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-11-04 21:41:51.989521: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-11-04 21:41:51.989746: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpyy_yy8a4\n",
      "2023-11-04 21:41:51.995336: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-11-04 21:41:51.995389: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpyy_yy8a4\n",
      "2023-11-04 21:41:52.014643: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-11-04 21:41:52.152638: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpyy_yy8a4\n",
      "2023-11-04 21:41:52.186359: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 196614 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model2)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# REVIEW This\n",
    "# converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter2.inference_input_type = tf.int8  # or tf.uint8\n",
    "# converter2.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "quantized_tflite_model2 = converter2.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1e33e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoeqcr7cp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoeqcr7cp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model in Mb: 0.7056655883789062\n",
      "Quantized model in Mb: 0.6127700805664062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 21:41:56.257106: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-11-04 21:41:56.257146: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-11-04 21:41:56.257370: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpoeqcr7cp\n",
      "2023-11-04 21:41:56.259804: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-11-04 21:41:56.259829: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpoeqcr7cp\n",
      "2023-11-04 21:41:56.267058: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-11-04 21:41:56.304451: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpoeqcr7cp\n",
      "2023-11-04 21:41:56.318629: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 61259 microseconds.\n"
     ]
    }
   ],
   "source": [
    "### TODO: Abstract this into a function\n",
    "# Create float TFLite model\n",
    "float_converter_base = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "float_tflite_model_base = float_converter_base.convert()\n",
    "\n",
    "# Measure sizes of models.\n",
    "_, float_base_file = tempfile.mkstemp('.tflite')\n",
    "_, quant2_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant2_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model2)\n",
    "\n",
    "with open(float_base_file, 'wb') as f:\n",
    "  f.write(float_tflite_model_base)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_base_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant2_file) / float(2**20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
